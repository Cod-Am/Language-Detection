{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Detection\n",
    "The task of the model is to detect language given as input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "import string\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,precision_score,confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import BaggingClassifier,ExtraTreesClassifier,AdaBoostClassifier,HistGradientBoostingClassifier,GradientBoostingClassifier,RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB,BernoulliNB,MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# initializing the tools\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "punctuations=string.punctuation\n",
    "tfidf=TfidfVectorizer()\n",
    "le=LabelEncoder()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"lang detection/Language Detection.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nature, in the broadest sense, is the natural...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Nature\" can refer to the phenomena of the phy...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The study of nature is a large, if not the onl...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Although humans are part of nature, human acti...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1] The word nature is borrowed from the Old F...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Language\n",
       "0   Nature, in the broadest sense, is the natural...  English\n",
       "1  \"Nature\" can refer to the phenomena of the phy...  English\n",
       "2  The study of nature is a large, if not the onl...  English\n",
       "3  Although humans are part of nature, human acti...  English\n",
       "4  [1] The word nature is borrowed from the Old F...  English"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10337 entries, 0 to 10336\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Text      10337 non-null  object\n",
      " 1   Language  10337 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 161.6+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Language\n",
       "English       1385\n",
       "French        1014\n",
       "Spanish        819\n",
       "Portugeese     739\n",
       "Italian        698\n",
       "Russian        692\n",
       "Sweedish       676\n",
       "Malayalam      594\n",
       "Dutch          546\n",
       "Arabic         536\n",
       "Turkish        474\n",
       "German         470\n",
       "Tamil          469\n",
       "Danish         428\n",
       "Kannada        369\n",
       "Greek          365\n",
       "Hindi           63\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.value_counts(subset='Language')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(obj):\n",
    "    words=word_tokenize(obj)\n",
    "    corpus=[word for word in words if word not in punctuations]\n",
    "    corpus=[word.lower() for word in corpus]   \n",
    "    corpus=' '.join(corpus)\n",
    "    lemmatizer.lemmatize(corpus)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Text']=dataset['Text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=le.fit_transform(dataset['Language'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10337x39917 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 163192 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors=tfidf.fit_transform(dataset['Text'])\n",
    "vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors=vectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nestimators=int(len(tfidf.get_feature_names_out())*0.5)\n",
    "# initializing the models\n",
    "bagging=BaggingClassifier(n_estimators=nestimators)\n",
    "extra_trees=ExtraTreesClassifier(n_estimators=nestimators)\n",
    "# ada=AdaBoostClassifier()\n",
    "# histo_grad=HistGradientBoostingClassifier()\n",
    "rfc=RandomForestClassifier(n_estimators=nestimators)\n",
    "gradient=GradientBoostingClassifier(n_estimators=nestimators)\n",
    "mlpc=MLPClassifier()\n",
    "gnb=GaussianNB()\n",
    "mnb=MultinomialNB()\n",
    "bnb=BernoulliNB()\n",
    "\n",
    "clfs={\n",
    "    # 'Extra Trees':extra_trees,\n",
    "    # 'Ada Boost':ada,\n",
    "    # 'Random Forest':rfc,\n",
    "    # 'Gradient Boost':gradient,\n",
    "    'MLP':mlpc,\n",
    "    'Gaussian Naive Bayes':gnb,\n",
    "    'Multinomial Naive Bayes':mnb,\n",
    "    'Bernoulli Naive Bayes':bnb\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: MLP\n",
      "Model training completed\n",
      "Accuracy: 0.9584139264990329\n",
      "Precision: 0.9767796308879578\n",
      "Model: Gaussian Naive Bayes\n",
      "Model training completed\n",
      "Accuracy: 0.9787234042553191\n",
      "Precision: 0.9802463670842443\n",
      "Model: Multinomial Naive Bayes\n",
      "Model training completed\n",
      "Accuracy: 0.9468085106382979\n",
      "Precision: 0.9563969500017051\n",
      "Model: Bernoulli Naive Bayes\n",
      "Model training completed\n",
      "Accuracy: 0.5203094777562862\n",
      "Precision: 0.865611165447317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\IDEs\\anaconda\\envs\\language-detection\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "for name,clf in clfs.items():\n",
    "    print(f'Model: {name}')\n",
    "    clf.fit(xtrain,ytrain)\n",
    "    ypred=clf.predict(xtest)\n",
    "    print('Model training completed')\n",
    "    print(f'Accuracy: {accuracy_score(ytest,ypred)}')\n",
    "    print(f'Precision: {precision_score(ytest, ypred, average=\"weighted\")}')\n",
    "    # print(f'Confusion Matrix:\\n{confusion_matrix(ytest,ypred)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(gnb, open('gnb_model.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "language-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
